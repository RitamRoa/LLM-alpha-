# LLM-alpha-
this is me just working on downloading and running lightweight models in my 8gb ram laptop. 


how do you run it?

just clone the repo 
git clone https://github.com/RitamRoa/LLM-alpha-.git

install the requirements i.e.

pip install requests pyinstaller

later 
just run it using the command 
python quant_assistant.py 

name in working :)

if you want to contribute i would suggest a CONTRIBUTING.md file and then submit a pr, which will be scrutinized and reviews within 24 hours. 

more upgrades coming to this when i get my hands on a better laptop as i want this to be full-scaled llm running locally on my laptop ?

future implementations:
1. Complete running .exe windows application.
2. running better models rather than llama 3.2 instruct and qwen coder 2.5 3B
3. a complete terminal (better colors than green and black) based ui, with menus where one can select the model to code, reason, personal (password protected), random and diary
4. diary is basically my day2day activities which is stored and made note of. Now this is used and stored in chromadb (less <1mb per year) by the model.
5. personal & diary stores memory (personal has the option to not).
6. deep research with web
7. vpn based search
8. uncensored

for now i can only come up with this much features will be updating if i keep getting in my mind.
